{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import namedtuple\n",
    "from copy import deepcopy\n",
    "import math\n",
    "\n",
    "\n",
    "def read_json(filename):\n",
    "    with Path(filename).open(encoding='utf8') as handle:\n",
    "        ann = json.load(handle)\n",
    "    return ann\n",
    "\n",
    "# chinese, thai, vietnamese, japanese\n",
    "language = \"thai\"\n",
    "\n",
    "# 대회 학습 데이터로 주어진 태국어 영수증으로 테스트 진행.\n",
    "# 자신의 경로에 맞게 파일 경로를 수정.\n",
    "# ground truth와 prediction 파일 경로 설정\n",
    "gt_path = f\"./data/{language}_receipt/ufo/val.json\"\n",
    "pred_path = f\"./data/{language}_receipt/ufo/thai_val_predict.json\"\n",
    "\n",
    "# gt와 pred 데이터를 읽어오기\n",
    "gt_data = read_json(gt_path)\n",
    "pred_data = read_json(pred_path)\n",
    "\n",
    "# 필요한 형식으로 gt와 pred 데이터를 변환\n",
    "gt_dict = {image_id: [word['points'] for word in data['words'].values()]\n",
    "           for image_id, data in gt_data['images'].items()}\n",
    "pred_dict = {image_id: [word['points'] for word in data['words'].values()]\n",
    "             for image_id, data in pred_data['images'].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_evaluation_params():\n",
    "    \"\"\"\n",
    "    default_evaluation_params: Default parameters to use for the validation and evaluation.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'AREA_RECALL_CONSTRAINT': 0.8,\n",
    "        'AREA_PRECISION_CONSTRAINT': 0.4,\n",
    "        'EV_PARAM_IND_CENTER_DIFF_THR': 1,\n",
    "        'MTYPE_OO_O': 1.,\n",
    "        'MTYPE_OM_O': 0.8,\n",
    "        'MTYPE_OM_M': 1.,\n",
    "        'GT_SAMPLE_NAME_2_ID': 'gt_img_([0-9]+).txt',\n",
    "        'DET_SAMPLE_NAME_2_ID': 'res_img_([0-9]+).txt',\n",
    "        'CRLF': False  # Lines are delimited by Windows CRLF format\n",
    "    }\n",
    "\n",
    "def calc_deteval_metrics(pred_bboxes_dict, gt_bboxes_dict, transcriptions_dict=None,\n",
    "                         eval_hparams=None, bbox_format='rect', verbose=False):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    pred_bboxes_dict (dict): 각 샘플에 대한 예측된 bounding box의 딕셔너리.\n",
    "    gt_bboxes_dict (dict): 각 샘플에 대한 실제 정답(ground truth) bouding box의 딕셔너리.\n",
    "    transcriptions_dict (dict, 선택적): 각 샘플에 대한 텍스트 전사(transcription)의 딕셔너리.\n",
    "    eval_hparams (dict, 선택적): 평가 하이퍼파라미터.\n",
    "    bbox_format (str, 선택적): bounding box의 형식. 기본값은 'rect'.\n",
    "    verbose (bool, 선택적): True일 경우, 출력에 상세한 평가 로그를 포함.\n",
    "\n",
    "    Returns:\n",
    "    dict: 계산된 메트릭과 기타 평가 정보를 포함하는 딕셔너리.\n",
    "\n",
    "    Note:\n",
    "    현재는 rect(xmin, ymin, xmax, ymax) 형식의 bounding box만 지원함. 다른 형식(quadrilateral, polygon, etc.)의 데이터가 들어오면 외접하는 rect로 변환해서 이용하고 있음.\n",
    "    \"\"\"\n",
    "\n",
    "    def one_to_one_match(row, col):\n",
    "        cont = 0\n",
    "        for j in range(len(recallMat[0])):\n",
    "            if recallMat[row, j] >= eval_hparams['AREA_RECALL_CONSTRAINT'] and precisionMat[row, j] >= eval_hparams['AREA_PRECISION_CONSTRAINT']:\n",
    "                cont = cont + 1\n",
    "        if (cont != 1):\n",
    "            return False\n",
    "        cont = 0\n",
    "        for i in range(len(recallMat)):\n",
    "            if recallMat[i, col] >= eval_hparams['AREA_RECALL_CONSTRAINT'] and precisionMat[i, col] >= eval_hparams['AREA_PRECISION_CONSTRAINT']:\n",
    "                cont = cont + 1\n",
    "        if (cont != 1):\n",
    "            return False\n",
    "\n",
    "        if recallMat[row, col] >= eval_hparams['AREA_RECALL_CONSTRAINT'] and precisionMat[row, col] >= eval_hparams['AREA_PRECISION_CONSTRAINT']:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def num_overlaps_gt(gtNum):\n",
    "        cont = 0\n",
    "        for detNum in range(len(detRects)):\n",
    "            if detNum not in detDontCareRectsNum:\n",
    "                if recallMat[gtNum, detNum] > 0:\n",
    "                    cont = cont + 1\n",
    "        return cont\n",
    "\n",
    "    def num_overlaps_det(detNum):\n",
    "        cont = 0\n",
    "        for gtNum in range(len(recallMat)):\n",
    "            if gtNum not in gtDontCareRectsNum:\n",
    "                if recallMat[gtNum, detNum] > 0:\n",
    "                    cont = cont + 1\n",
    "        return cont\n",
    "\n",
    "    def is_single_overlap(row, col):\n",
    "        if num_overlaps_gt(row) == 1 and num_overlaps_det(col) == 1:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def one_to_many_match(gtNum):\n",
    "        many_sum = 0\n",
    "        detRects = []\n",
    "        for detNum in range(len(recallMat[0])):\n",
    "            if gtRectMat[gtNum] == 0 and detRectMat[detNum] == 0 and detNum not in detDontCareRectsNum:\n",
    "                if precisionMat[gtNum, detNum] >= eval_hparams['AREA_PRECISION_CONSTRAINT']:\n",
    "                    many_sum += recallMat[gtNum, detNum]\n",
    "                    detRects.append(detNum)\n",
    "        if round(many_sum, 4) >= eval_hparams['AREA_RECALL_CONSTRAINT']:\n",
    "            return True, detRects\n",
    "        else:\n",
    "            return False, []\n",
    "\n",
    "    def many_to_one_match(detNum):\n",
    "        many_sum = 0\n",
    "        gtRects = []\n",
    "        for gtNum in range(len(recallMat)):\n",
    "            if gtRectMat[gtNum] == 0 and detRectMat[detNum] == 0 and gtNum not in gtDontCareRectsNum:\n",
    "                if recallMat[gtNum, detNum] >= eval_hparams['AREA_RECALL_CONSTRAINT']:\n",
    "                    many_sum += precisionMat[gtNum, detNum]\n",
    "                    gtRects.append(gtNum)\n",
    "        if round(many_sum, 4) >= eval_hparams['AREA_PRECISION_CONSTRAINT']:\n",
    "            return True, gtRects\n",
    "        else:\n",
    "            return False, []\n",
    "\n",
    "    def area(a, b):\n",
    "        dx = min(a.xmax, b.xmax) - max(a.xmin, b.xmin) + 1\n",
    "        dy = min(a.ymax, b.ymax) - max(a.ymin, b.ymin) + 1\n",
    "        if (dx >= 0) and (dy >= 0):\n",
    "            return dx*dy\n",
    "        else:\n",
    "            return 0.\n",
    "\n",
    "    def center(r):\n",
    "        x = float(r.xmin) + float(r.xmax - r.xmin + 1) / 2.\n",
    "        y = float(r.ymin) + float(r.ymax - r.ymin + 1) / 2.\n",
    "        return Point(x, y)\n",
    "\n",
    "    def point_distance(r1, r2):\n",
    "        distx = math.fabs(r1.x - r2.x)\n",
    "        disty = math.fabs(r1.y - r2.y)\n",
    "        return math.sqrt(distx * distx + disty * disty)\n",
    "\n",
    "    def center_distance(r1, r2):\n",
    "        return point_distance(center(r1), center(r2))\n",
    "\n",
    "    def diag(r):\n",
    "        w = (r.xmax - r.xmin + 1)\n",
    "        h = (r.ymax - r.ymin + 1)\n",
    "        return math.sqrt(h * h + w * w)\n",
    "\n",
    "    if eval_hparams is None:\n",
    "        eval_hparams = default_evaluation_params()\n",
    "\n",
    "    if bbox_format != 'rect':\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # bbox가 다른 형식일 경우 rect 형식으로 변환\n",
    "    _pred_bboxes_dict, _gt_bboxes_dict = deepcopy(pred_bboxes_dict), deepcopy(gt_bboxes_dict)\n",
    "    pred_bboxes_dict, gt_bboxes_dict = dict(), dict()\n",
    "    for sample_name, bboxes in _pred_bboxes_dict.items():\n",
    "        # 이미 rect 형식일 경우 변환하지 않고 그대로 사용\n",
    "        if len(bboxes) > 0 and np.array(bboxes[0]).ndim == 1 and len(bboxes[0]) == 4:\n",
    "            pred_bboxes_dict = _pred_bboxes_dict\n",
    "            break\n",
    "\n",
    "        pred_bboxes_dict[sample_name] = []\n",
    "        for bbox in map(np.array, bboxes):\n",
    "            rect = [bbox[:, 0].min(), bbox[:, 1].min(), bbox[:, 0].max(), bbox[:, 1].max()]\n",
    "            pred_bboxes_dict[sample_name].append(rect)\n",
    "    for sample_name, bboxes in _gt_bboxes_dict.items():\n",
    "        if len(bboxes) > 0 and np.array(bboxes[0]).ndim == 1 and len(bboxes[0]) == 4:\n",
    "            gt_bboxes_dict = _gt_bboxes_dict\n",
    "            break\n",
    "\n",
    "        gt_bboxes_dict[sample_name] = []\n",
    "        for bbox in map(np.array, bboxes):\n",
    "            rect = [bbox[:, 0].min(), bbox[:, 1].min(), bbox[:, 0].max(), bbox[:, 1].max()]\n",
    "            gt_bboxes_dict[sample_name].append(rect)\n",
    "\n",
    "    perSampleMetrics = {}\n",
    "\n",
    "    methodRecallSum = 0\n",
    "    methodPrecisionSum = 0\n",
    "\n",
    "    Rectangle = namedtuple('Rectangle', 'xmin ymin xmax ymax')\n",
    "    Point = namedtuple('Point', 'x y')\n",
    "\n",
    "    numGt = 0\n",
    "    numDet = 0\n",
    "\n",
    "    # ground truth 딕셔너리의 각 샘플에 대해 반복\n",
    "    for sample_name in gt_bboxes_dict:\n",
    "\n",
    "        recall = 0\n",
    "        precision = 0\n",
    "        hmean = 0\n",
    "        recallAccum = 0.\n",
    "        precisionAccum = 0.\n",
    "        gtRects = []\n",
    "        detRects = []\n",
    "        gtPolPoints = []\n",
    "        detPolPoints = []\n",
    "        gtDontCareRectsNum = []  # Array of Ground Truth Rectangles' keys marked as don't care\n",
    "        detDontCareRectsNum = []  # Array of Detected Rectangles' matched with a don't care GT\n",
    "        pairs = []\n",
    "        evaluationLog = \"\"\n",
    "\n",
    "        recallMat = np.empty([1, 1])\n",
    "        precisionMat = np.empty([1, 1])\n",
    "\n",
    "        pointsList = gt_bboxes_dict[sample_name]\n",
    "\n",
    "        if transcriptions_dict is None:\n",
    "            transcriptionsList = None\n",
    "        else:\n",
    "            transcriptionsList = transcriptions_dict[sample_name]\n",
    "\n",
    "        for n in range(len(pointsList)):\n",
    "            points = pointsList[n]\n",
    "            transcription = transcriptionsList[n] if transcriptionsList else None\n",
    "            dontCare = transcription == \"###\" if transcription else False\n",
    "            gtRect = Rectangle(*points)\n",
    "            gtRects.append(gtRect)\n",
    "            gtPolPoints.append(np.array(points).tolist())\n",
    "            if dontCare:\n",
    "                gtDontCareRectsNum.append(len(gtRects)-1)\n",
    "\n",
    "        evaluationLog += \"GT rectangles: \" + \\\n",
    "            str(len(gtRects)) + (\" (\" + str(len(gtDontCareRectsNum)) +\n",
    "                                 \" don't care)\\n\" if len(gtDontCareRectsNum) > 0 else \"\\n\")\n",
    "\n",
    "        if sample_name in pred_bboxes_dict:\n",
    "            pointsList = pred_bboxes_dict[sample_name]\n",
    "\n",
    "            for n in range(len(pointsList)):\n",
    "                points = pointsList[n]\n",
    "                detRect = Rectangle(*points)\n",
    "                detRects.append(detRect)\n",
    "                detPolPoints.append(np.array(points).tolist())\n",
    "                if len(gtDontCareRectsNum) > 0:\n",
    "                    for dontCareRectNum in gtDontCareRectsNum:\n",
    "                        dontCareRect = gtRects[dontCareRectNum]\n",
    "                        intersected_area = area(dontCareRect, detRect)\n",
    "                        rdDimensions = ((detRect.xmax - detRect.xmin+1) * (detRect.ymax - detRect.ymin+1))\n",
    "                        if (rdDimensions == 0):\n",
    "                            precision = 0\n",
    "                        else:\n",
    "                            precision = intersected_area / rdDimensions\n",
    "                        if (precision > eval_hparams['AREA_PRECISION_CONSTRAINT']):\n",
    "                            detDontCareRectsNum.append(len(detRects)-1)\n",
    "                            break\n",
    "\n",
    "            evaluationLog += \"DET rectangles: \" + \\\n",
    "                str(len(detRects)) + (\" (\" + str(len(detDontCareRectsNum)) +\n",
    "                                      \" don't care)\\n\" if len(detDontCareRectsNum) > 0 else \"\\n\")\n",
    "\n",
    "            if len(gtRects) == 0:\n",
    "                recall = 1\n",
    "                precision = 0 if len(detRects) > 0 else 1\n",
    "\n",
    "            # Recall 과 precision 매트릭스를 계산\n",
    "            if len(detRects) > 0:\n",
    "                outputShape = [len(gtRects), len(detRects)]\n",
    "                recallMat = np.empty(outputShape)\n",
    "                precisionMat = np.empty(outputShape)\n",
    "                gtRectMat = np.zeros(len(gtRects), np.int8)\n",
    "                detRectMat = np.zeros(len(detRects), np.int8)\n",
    "                for gtNum in range(len(gtRects)):\n",
    "                    for detNum in range(len(detRects)):\n",
    "                        rG = gtRects[gtNum]\n",
    "                        rD = detRects[detNum]\n",
    "                        intersected_area = area(rG, rD)\n",
    "                        rgDimensions = ((rG.xmax - rG.xmin+1) * (rG.ymax - rG.ymin+1))\n",
    "                        rdDimensions = ((rD.xmax - rD.xmin+1) * (rD.ymax - rD.ymin+1))\n",
    "                        recallMat[gtNum, detNum] = 0 if rgDimensions == 0 else intersected_area / rgDimensions\n",
    "                        precisionMat[gtNum, detNum] = 0 if rdDimensions == 0 else intersected_area / rdDimensions\n",
    "\n",
    "                # Find one-to-one matches\n",
    "                evaluationLog += \"Find one-to-one matches\\n\"\n",
    "                for gtNum in range(len(gtRects)):\n",
    "                    for detNum in range(len(detRects)):\n",
    "                        if gtRectMat[gtNum] == 0 and detRectMat[detNum] == 0 and gtNum not in gtDontCareRectsNum and detNum not in detDontCareRectsNum:\n",
    "                            match = one_to_one_match(gtNum, detNum)\n",
    "                            if match is True:\n",
    "                                # in deteval we have to make other validation before mark as one-to-one\n",
    "                                if is_single_overlap(gtNum, detNum) is True:\n",
    "                                    rG = gtRects[gtNum]\n",
    "                                    rD = detRects[detNum]\n",
    "                                    normDist = center_distance(rG, rD)\n",
    "                                    normDist /= diag(rG) + diag(rD)\n",
    "                                    normDist *= 2.0\n",
    "                                    if normDist < eval_hparams['EV_PARAM_IND_CENTER_DIFF_THR']:\n",
    "                                        gtRectMat[gtNum] = 1\n",
    "                                        detRectMat[detNum] = 1\n",
    "                                        recallAccum += eval_hparams['MTYPE_OO_O']\n",
    "                                        precisionAccum += eval_hparams['MTYPE_OO_O']\n",
    "                                        pairs.append({'gt': gtNum, 'det': detNum, 'type': 'OO'})\n",
    "                                        evaluationLog += \"Match GT #\" + str(gtNum) + \" with Det #\" + str(detNum) + \"\\n\"\n",
    "                                    else:\n",
    "                                        evaluationLog += \"Match Discarded GT #\" + \\\n",
    "                                            str(gtNum) + \" with Det #\" + str(detNum) + \\\n",
    "                                            \" normDist: \" + str(normDist) + \" \\n\"\n",
    "                                else:\n",
    "                                    evaluationLog += \"Match Discarded GT #\" + \\\n",
    "                                        str(gtNum) + \" with Det #\" + str(detNum) + \" not single overlap\\n\"\n",
    "                # Find one-to-many matches\n",
    "                evaluationLog += \"Find one-to-many matches\\n\"\n",
    "                for gtNum in range(len(gtRects)):\n",
    "                    if gtNum not in gtDontCareRectsNum:\n",
    "                        match, matchesDet = one_to_many_match(gtNum)\n",
    "                        if match is True:\n",
    "                            evaluationLog += \"num_overlaps_gt=\" + str(num_overlaps_gt(gtNum))\n",
    "                            # deteval에서는 일대일(one-to-one) 매핑으로 표시하기 전에 유효성 검사를 진행\n",
    "                            if num_overlaps_gt(gtNum) >= 2:\n",
    "                                gtRectMat[gtNum] = 1\n",
    "                                recallAccum += (eval_hparams['MTYPE_OO_O'] if len(matchesDet)\n",
    "                                                == 1 else eval_hparams['MTYPE_OM_O'])\n",
    "                                precisionAccum += (eval_hparams['MTYPE_OO_O'] if len(matchesDet)\n",
    "                                                   == 1 else eval_hparams['MTYPE_OM_O']*len(matchesDet))\n",
    "                                pairs.append({'gt': gtNum, 'det': matchesDet,\n",
    "                                             'type': 'OO' if len(matchesDet) == 1 else 'OM'})\n",
    "                                for detNum in matchesDet:\n",
    "                                    detRectMat[detNum] = 1\n",
    "                                evaluationLog += \"Match GT #\" + str(gtNum) + \" with Det #\" + str(matchesDet) + \"\\n\"\n",
    "                            else:\n",
    "                                evaluationLog += \"Match Discarded GT #\" + \\\n",
    "                                    str(gtNum) + \" with Det #\" + str(matchesDet) + \" not single overlap\\n\"\n",
    "\n",
    "                # Find many-to-one matches\n",
    "                evaluationLog += \"Find many-to-one matches\\n\"\n",
    "                for detNum in range(len(detRects)):\n",
    "                    if detNum not in detDontCareRectsNum:\n",
    "                        match, matchesGt = many_to_one_match(detNum)\n",
    "                        if match is True:\n",
    "                          # deteval에서는 일대일(one-to-one) 매핑으로 표시하기 전에 유효성 검사를 진행\n",
    "                            if num_overlaps_det(detNum) >= 2:\n",
    "                                detRectMat[detNum] = 1\n",
    "                                recallAccum += (eval_hparams['MTYPE_OO_O'] if len(matchesGt)\n",
    "                                                == 1 else eval_hparams['MTYPE_OM_M']*len(matchesGt))\n",
    "                                precisionAccum += (eval_hparams['MTYPE_OO_O']\n",
    "                                                   if len(matchesGt) == 1 else eval_hparams['MTYPE_OM_M'])\n",
    "                                pairs.append({'gt': matchesGt, 'det': detNum,\n",
    "                                             'type': 'OO' if len(matchesGt) == 1 else 'MO'})\n",
    "                                for gtNum in matchesGt:\n",
    "                                    gtRectMat[gtNum] = 1\n",
    "                                evaluationLog += \"Match GT #\" + str(matchesGt) + \" with Det #\" + str(detNum) + \"\\n\"\n",
    "                            else:\n",
    "                                evaluationLog += \"Match Discarded GT #\" + \\\n",
    "                                    str(matchesGt) + \" with Det #\" + str(detNum) + \" not single overlap\\n\"\n",
    "\n",
    "                # 해당 샘플에 대한 최종 메트릭 계산\n",
    "                numGtCare = (len(gtRects) - len(gtDontCareRectsNum))\n",
    "                if numGtCare == 0:\n",
    "                    recall = float(1)\n",
    "                    precision = float(0) if len(detRects) > 0 else float(1)\n",
    "                else:\n",
    "                    recall = float(recallAccum) / numGtCare\n",
    "                    precision = float(0) if (len(detRects) - len(detDontCareRectsNum)\n",
    "                                             ) == 0 else float(precisionAccum) / (len(detRects) - len(detDontCareRectsNum))\n",
    "                hmean = 0 if (precision + recall) == 0 else 2.0 * precision * recall / (precision + recall)\n",
    "\n",
    "        # 전체 데이터에 대한 최종 메트릭 계산\n",
    "        methodRecallSum += recallAccum\n",
    "        methodPrecisionSum += precisionAccum\n",
    "        numGt += len(gtRects) - len(gtDontCareRectsNum)\n",
    "        numDet += len(detRects) - len(detDontCareRectsNum)\n",
    "\n",
    "        perSampleMetrics[sample_name] = {\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'hmean': hmean,\n",
    "            'pairs': pairs,\n",
    "            'recall_matrix': [] if len(detRects) > 100 else recallMat.tolist(),\n",
    "            'precision_matrix': [] if len(detRects) > 100 else precisionMat.tolist(),\n",
    "            'gt_bboxes': gtPolPoints,\n",
    "            'det_bboxes': detPolPoints,\n",
    "            'gt_dont_care': gtDontCareRectsNum,\n",
    "            'det_dont_care': detDontCareRectsNum,\n",
    "        }\n",
    "\n",
    "        if verbose:\n",
    "            perSampleMetrics[sample_name].update(evaluation_log=evaluationLog)\n",
    "\n",
    "    methodRecall = 0 if numGt == 0 else methodRecallSum/numGt\n",
    "    methodPrecision = 0 if numDet == 0 else methodPrecisionSum/numDet\n",
    "    methodHmean = 0 if methodRecall + methodPrecision == 0 else 2 * \\\n",
    "        methodRecall * methodPrecision / (methodRecall + methodPrecision)\n",
    "\n",
    "    methodMetrics = {'precision': methodPrecision, 'recall': methodRecall, 'hmean': methodHmean}\n",
    "\n",
    "    resDict = {'calculated': True, 'Message': '', 'total': methodMetrics,\n",
    "               'per_sample': perSampleMetrics, 'eval_hparams': eval_hparams}\n",
    "\n",
    "    return resDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Evaluation Metrics:\n",
      "Precision: 0.6745\n",
      "Recall: 0.7281\n",
      "Hmean: 0.7003\n",
      "\n",
      "Detailed per-sample Metrics:\n",
      "language =  thai\n",
      "extractor.th.in_house.appen_000584_page0001.jpg: Precision=0.6929, Recall=0.7480, Hmean=0.7194\n",
      "language =  thai\n",
      "extractor.th.in_house.appen_000290_page0001.jpg: Precision=0.4986, Recall=0.5660, Hmean=0.5302\n",
      "language =  thai\n",
      "extractor.th.in_house.appen_000991_page0001.jpg: Precision=0.7728, Recall=0.7600, Hmean=0.7664\n",
      "language =  thai\n",
      "extractor.th.in_house.appen_000228_page0001.jpg: Precision=0.8000, Recall=0.5791, Hmean=0.6719\n",
      "language =  thai\n",
      "extractor.th.in_house.appen_000293_page0001.jpg: Precision=0.7325, Recall=0.8909, Hmean=0.8040\n",
      "language =  thai\n",
      "extractor.th.in_house.appen_000169_page0001.jpg: Precision=0.8644, Recall=0.9000, Hmean=0.8818\n",
      "language =  thai\n",
      "extractor.th.in_house.appen_000361_page0001.jpg: Precision=0.7484, Recall=0.9316, Hmean=0.8300\n",
      "language =  thai\n",
      "extractor.th.in_house.appen_000278_page0001.jpg: Precision=0.8000, Recall=0.8000, Hmean=0.8000\n",
      "language =  thai\n",
      "extractor.th.in_house.appen_000318_page0001.jpg: Precision=0.5733, Recall=0.5778, Hmean=0.5755\n",
      "language =  thai\n",
      "extractor.th.in_house.appen_001003_page0001.jpg: Precision=0.7362, Recall=0.7125, Hmean=0.7242\n",
      "language =  thai\n",
      "extractor.th.in_house.appen_000030_page0001.jpg: Precision=0.7492, Recall=0.6263, Hmean=0.6823\n",
      "language =  thai\n",
      "extractor.th.in_house.appen_000218_page0001.jpg: Precision=0.7314, Recall=0.6176, Hmean=0.6697\n",
      "language =  thai\n",
      "extractor.th.in_house.appen_000360_page0001.jpg: Precision=0.7342, Recall=0.9103, Hmean=0.8129\n",
      "language =  thai\n",
      "extractor.th.in_house.appen_001016_page0001.jpg: Precision=0.6337, Recall=0.8397, Hmean=0.7223\n",
      "language =  thai\n",
      "extractor.th.in_house.appen_000629_page0001.jpg: Precision=0.8141, Recall=0.9182, Hmean=0.8630\n",
      "language =  thai\n",
      "extractor.th.in_house.appen_000750_page0001.jpg: Precision=0.5974, Recall=0.6638, Hmean=0.6288\n",
      "language =  thai\n",
      "extractor.th.in_house.appen_000540_page0001.jpg: Precision=0.5306, Recall=0.5761, Hmean=0.5524\n",
      "language =  thai\n",
      "extractor.th.in_house.appen_000178_page0001.jpg: Precision=0.4558, Recall=0.5523, Hmean=0.4994\n",
      "language =  thai\n",
      "extractor.th.in_house.appen_000648_page0001.jpg: Precision=0.3774, Recall=0.3490, Hmean=0.3627\n",
      "language =  thai\n",
      "extractor.th.in_house.appen_000721_page0001.jpg: Precision=0.6860, Recall=0.7195, Hmean=0.7024\n"
     ]
    }
   ],
   "source": [
    "# calc_deteval_metrics 함수를 이용하여 gt와 pred 비교\n",
    "eval_params = default_evaluation_params()\n",
    "results = calc_deteval_metrics(pred_dict, gt_dict, transcriptions_dict=None,\n",
    "                               eval_hparams=eval_params, bbox_format='rect', verbose=True)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"Overall Evaluation Metrics:\")\n",
    "print(\"language = \", language)\n",
    "print(f\"Precision: {results['total']['precision']:.4f}\")\n",
    "print(f\"Recall: {results['total']['recall']:.4f}\")\n",
    "print(f\"Hmean: {results['total']['hmean']:.4f}\")\n",
    "\n",
    "# 이미지별 상세 메트릭 출력\n",
    "print(\"\\nDetailed per-sample Metrics:\")\n",
    "for sample_name, metrics in results['per_sample'].items():\n",
    "    print(\n",
    "        f\"{sample_name}: Precision={metrics['precision']:.4f}, Recall={metrics['recall']:.4f}, Hmean={metrics['hmean']:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
